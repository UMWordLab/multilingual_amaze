{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UMWordLab/multilingual_amaze/blob/main/Multilingual_A_maze_Alternative_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT-based Multilingual A-maze Alternative Generation"
      ],
      "metadata": {
        "id": "Z73vI8yCq3Xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preliminaries\n",
        "Please run the following cells to install and import the necessary libraries. "
      ],
      "metadata": {
        "id": "mOTp2Xr4spnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV5teS5-uEoC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install minicons\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVtYtp7xuWv7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "from minicons import scorer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForMaskedLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Selecting a Minicons language model\n",
        "Please run the following cell and input the language model you would like to use for the experiment.\n"
      ],
      "metadata": {
        "id": "Mzcm2K-js8Lx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mRA16lk3ESC"
      },
      "outputs": [],
      "source": [
        "langmodel = input(\"What minicons language model would you like to use?\\nYou can select any from this list: https://huggingface.co/models\\nThe name of the model can be copied using the clipboard icon next to the name on the webpage.\\n\")\n",
        "print(langmodel, \"selected as model.\")\n",
        "model = scorer.IncrementalLMScorer(langmodel, 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained(langmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. A few things before we begin...\n",
        "Please run the following cells and answer the questions before moving onto the main functions. They will be asking for input CSV files for frequency mapping and stimuli. Please consult the documentation for specifications regarding these files."
      ],
      "metadata": {
        "id": "r4wMAoh0thYs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0G7O6tCfGLJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print(\"Please upload your file that contains the word-to-frequency mapping.\")\n",
        "uploaded = files.upload()\n",
        "freq_file = next(iter(uploaded))\n",
        "freq_window = int(input(\"What is the window of frequency that you would like to use to consider words 'similar' frequency? \"))\n",
        "\n",
        "import csv\n",
        "import io\n",
        "\n",
        "# process input file\n",
        "def process_frequency_file(filename):\n",
        "  res = {}\n",
        "  with open(filename, mode='r', encoding='utf-8-sig') as csv_file:\n",
        "      csv_reader = csv.DictReader(csv_file)\n",
        "      for row in csv_reader:\n",
        "        freq = row['frequency']\n",
        "        word = row['word']\n",
        "        res[word] = freq\n",
        "  return res\n",
        "\n",
        "freq_dict = process_frequency_file(freq_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVdmj6QGdi-P"
      },
      "outputs": [],
      "source": [
        "print(\"Please upload your file that contains the stimuli sentences to be used for alternative generation\")\n",
        "uploaded = files.upload()\n",
        "stim_file = next(iter(uploaded))\n",
        "\n",
        "def process_stimuli_file(filename):\n",
        "  res = []\n",
        "  with open(filename, mode='r', encoding='utf-8-sig') as csv_file:\n",
        "      csv_reader = csv.DictReader(csv_file)\n",
        "      for row in csv_reader:\n",
        "          sent = row['sentences']\n",
        "          res.append(sent)\n",
        "  return res\n",
        "\n",
        "sentences = process_stimuli_file(stim_file)\n",
        "print(\"Stimuli saved. \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Main Functions\n",
        "- find_similar_frequency\n",
        "- tokenization\n",
        "- calculate_surprisal\n",
        "- find_alternative"
      ],
      "metadata": {
        "id": "CvXpnTGSyeQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rauIQVljSgC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "model = BertForMaskedLM.from_pretrained(langmodel)\n",
        "\n",
        "# instead of random selection, provide a window for frequency selection\n",
        "def find_similar_frequency(word, window):\n",
        "  res = []\n",
        "  if word in freq_dict.keys():\n",
        "    print('word exists in dict')\n",
        "    word_frq = freq_dict[word]\n",
        "    for w, f in freq_dict.items():\n",
        "      if w != word: \n",
        "        if int(word_frq) < (int(f) + window) and int(word_frq) > (int(f) - window):\n",
        "          res.append(w)\n",
        "          return res\n",
        "        else:\n",
        "          # error handling - word exists in given freq list but doesn't exist within the window\n",
        "          print('There weren\\'t words that matches the frequency in the given window. Next word will be chosen through random selection.')\n",
        "          res.append(random.choice(list(freq_dict.keys())))\n",
        "          return res\n",
        "  else:\n",
        "    # error handling - word doesn't exist in given frequency list\n",
        "    # complete random selection?\n",
        "    print('Frequency not found in list. Next word will be chosen through random selection.')\n",
        "    res.append(random.choice(list(freq_dict.keys())))\n",
        "  return res\n",
        "\n",
        "\n",
        "def tokenization(sentence, separation):\n",
        "  # tokenize each sentence\n",
        "  # for example, if we have a sentence consists of word AA B CCC DD\n",
        "  # we get, [ [[MASK][MASK] B CCC DD], [AA [MASK] CCC DD], [AA B [MASK][MASK][MASK] DD], [AA B CCC [MASK][MASK]]\n",
        "  masked_list = []\n",
        "  inputs = tokenizer(sentence, add_special_tokens=True, return_tensors=\"pt\") # we tokenize this sentence\n",
        "  mask_index = 0 # we keep track of where the [MASK] is\n",
        "  encoding = inputs['input_ids'].clone()\n",
        "  for i in range(len(separation)): # note that we don't replace code#101[CLS] or code#102[SEP]\n",
        "    masked_list.append(inputs['input_ids'].clone())\n",
        "    # We replace every word with code#103 which is the [MASK]\n",
        "    # note we +1 because we don't want to replace the [101] start of a sentence\n",
        "    masked_list[0][0][mask_index + 1] = 103\n",
        "    # increment mask_index to replace the next word with [MASK]\n",
        "    mask_index += 1\n",
        "  return masked_list\n",
        "\n",
        "def calculate_surprisal(sentence, word, token, start_position, verbose_mode):\n",
        "    inputs = tokenizer(sentence, is_split_into_words=True, add_special_tokens=True, return_tensors=\"pt\") # create a placeholder for masked sentences\n",
        "    inputs['input_ids'] = token  # replace placeholder with masked sentence\n",
        "    outputs = model(**inputs) # let the model predict\n",
        "    # find a list of similar frequency words\n",
        "    similar = find_similar_frequency(word, freq_window) \n",
        "    surprisal_list = []\n",
        "    # calculate surprisal of each word in similar[]\n",
        "    for word in similar:\n",
        "      i = 0\n",
        "      prob = 0\n",
        "      # tokenize the character (character -> id)\n",
        "      embeddings = tokenizer.convert_tokens_to_ids(word)\n",
        "      # actual position is the actual index\n",
        "      # we + 1 because of start_of_sentence token in BERT\n",
        "      actual_position = start_position + i\n",
        "      try:\n",
        "        word_weights = outputs[0][0][actual_position].squeeze().div(1.0).exp()\n",
        "        # if it is the first character, we set the probability to the first one\n",
        "        # else, we times current probability with previous one\n",
        "        if i == 0:\n",
        "          prob = (word_weights / sum(word_weights))[embeddings]\n",
        "        else:\n",
        "          prob = prob * (word_weights / sum(word_weights))[embeddings]\n",
        "        i = i + 1\n",
        "        if verbose_mode:\n",
        "          print(word, prob)\n",
        "        # now we have the probability, we calculate surprisal\n",
        "        surprisal_list.append(-1 * torch.log2(prob))\n",
        "      except:\n",
        "        surprisal_list.append(0.0)\n",
        "      \n",
        "    \n",
        "    # now we have a list of surprisal, find the highest one\n",
        "    max_val = max(surprisal_list)\n",
        "    max_index = surprisal_list.index(max_val)\n",
        "    print(similar[max_index], max_val)\n",
        "    return similar[max_index]\n",
        "\n",
        "def find_alternative(sentence, split):\n",
        "  result = []\n",
        "  # we get a list of [MASK] at different word position of a sentence\n",
        "  # detailed description in tokenization()\n",
        "  token_list = tokenization(sentence, split)\n",
        "  start_position = len(split)\n",
        "  for i in range(1, len(split)):\n",
        "    alternative = calculate_surprisal(sentence, split[i], token_list[i], start_position, verbose_mode=False)\n",
        "    result.append((split[i], alternative))\n",
        "    start_position = start_position + 1\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Alternative Generation\n",
        "\n",
        "This block runs the alternate generation and creates an output file under the name of your choosing. \n",
        "\n",
        "NOTE: THIS CELL WILL TAKE APPROXIMATELY 3 MINUTES **PER SENTENCE**. \n",
        "\n",
        "Make sure you check the sentences at the end after this block executes.\n",
        "\n",
        "Please run the following cell to generate the alternatives."
      ],
      "metadata": {
        "id": "WIIK-JPi5MSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outfile_name = input(\"What is the name of your output file? \")\n",
        "f = open(outfile_name, mode='a', encoding='utf-8-sig')\n",
        "writer = csv.writer(f)\n",
        "counter = 1\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  sentence = sentences[i]\n",
        "  result = find_alternative(sentence, sentence.split())\n",
        "  writer.writerow([counter, 0])\n",
        "  counter += 1\n",
        "  for pair in result:\n",
        "    writer.writerow(pair)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "rcqGMNAa5G6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmqJEPT3DhW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}